{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get started, copy over hyperparams from another experiment.\n",
    "# Visit rll.berkeley.edu/gps/hyperparams.html for documentation.\n",
    "\"\"\" Hyperparameters for UR trajectory optimization experiment. \"\"\"\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os.path\n",
    "import rospy\n",
    "from datetime import datetime\n",
    "from tf import TransformListener \n",
    "\n",
    "from gps import __file__ as gps_filepath\n",
    "from gps.agent.ur_ros.agent_ur import AgentPEPPER\n",
    "from gps.algorithm.algorithm_traj_opt import AlgorithmTrajOpt\n",
    "from gps.algorithm.cost.cost_fk import CostFK\n",
    "from gps.algorithm.cost.cost_sum import CostSum\n",
    "from gps.algorithm.cost.cost_utils import RAMP_LINEAR, RAMP_FINAL_ONLY\n",
    "from gps.algorithm.dynamics.dynamics_lr_prior import DynamicsLRPrior\n",
    "from gps.algorithm.dynamics.dynamics_prior_gmm import DynamicsPriorGMM\n",
    "from gps.algorithm.traj_opt.traj_opt_lqr_python import TrajOptLQRPython\n",
    "from gps.algorithm.policy.lin_gauss_init import init_lqr\n",
    "from gps.gui.target_setup_gui import load_pose_from_npz\n",
    "from gps.proto.gps_pb2 import JOINT_ANGLES, JOINT_VELOCITIES, \\\n",
    "        END_EFFECTOR_POINTS, END_EFFECTOR_POINT_VELOCITIES, ACTION, \\\n",
    "        TRIAL_ARM, JOINT_SPACE\n",
    "from gps.utility.general_utils import get_ee_points, get_position\n",
    "from gps.gui.config import generate_experiment_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics for the robot publisher and subscriber.\n",
    "JOINT_PUBLISHER  = '/arm_controller/command'\n",
    "JOINT_SUBSCRIBER = '/arm_controller/state'\n",
    "\n",
    "# 'SLOWNESS' is how far in the future (in seconds) position control extrapolates\n",
    "# when it publishs actions for robot movement.  1.0-10.0 is fine for simulation.\n",
    "SLOWNESS = 10.0\n",
    "# 'RESET_SLOWNESS' is how long (in seconds) we tell the robot to take when\n",
    "# returning to its start configuration.\n",
    "RESET_SLOWNESS = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants for joints\n",
    "L_SHOULDER_PITCH = 'LShoulderPitch'\n",
    "L_SHOULDER_ROLL = 'LShoulderRoll'\n",
    "L_ELBOW_YAW = 'LElbowYaw'\n",
    "L_ELBOW_ROLL = 'LElbowRoll'\n",
    "L_WRIST_YAW = 'LWristYaw'\n",
    "L_GRASP = 'LGrasp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants for links\n",
    "TORSO = 'torso'\n",
    "L_SHOULDER = 'LShoulder'\n",
    "L_BICEP = 'LBicep'\n",
    "L_ELBOW = 'LElbow'\n",
    "L_FOREARM = 'LForeArm'\n",
    "L_WRIST = 'l_wrist'\n",
    "L_GRIPPER = 'l_gripper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set end effector constants\n",
    "INITIAL_JOINTS = [1.5596, 0.12270, -1.22824, -0.5233, -0.0, 0.0]\n",
    "\n",
    "# Set the number of goal points. 1 by default for a single end effector tip.\n",
    "NUM_EE_POINTS = 1\n",
    "EE_POINTS = np.array([[0, 0, 0]])\n",
    "\n",
    "# Specify a goal state in cartesian coordinates.\n",
    "EE_POS_TGT = np.asmatrix([.70, .70, .50])\n",
    "\"\"\"UR 10 Examples:\n",
    "EE_POS_TGT = np.asmatrix([.29, .52, .62]) # Target where all joints are 0.\n",
    "EE_POS_TGT = np.asmatrix([.65, .80, .30]) # Target in positive octant near ground.\n",
    "EE_POS_TGT = np.asmatrix([.70, .70, .50]) # Target in positive octant used for debugging convergence.\n",
    "The Gazebo sim converges to the above point with non-action costs: \n",
    "(-589.75, -594.71, -599.54, -601.54, -602.75, -603.28, -604.28, -604.79, -605.55, -606.29)\n",
    "Distance from Goal: (0.014, 0.005, -0.017)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set end effector constants\n",
    "INITIAL_JOINTS = [0, -np.pi/2, np.pi/2, 0, 0, 0]\n",
    "\n",
    "# Set the number of goal points. 1 by default for a single end effector tip.\n",
    "NUM_EE_POINTS = 1\n",
    "EE_POINTS = np.array([[0, 0, 0]])\n",
    "\n",
    "# Specify a goal state in cartesian coordinates.\n",
    "EE_POS_TGT = np.asmatrix([0.31013, -0.251094, 0.07471])\n",
    "\"\"\"UR 10 Examples:\n",
    "EE_POS_TGT = np.asmatrix([.29, .52, .62]) # Target where all joints are 0.\n",
    "EE_POS_TGT = np.asmatrix([.65, .80, .30]) # Target in positive octant near ground.\n",
    "EE_POS_TGT = np.asmatrix([.70, .70, .50]) # Target in positive octant used for debugging convergence.\n",
    "The Gazebo sim converges to the above point with non-action costs: \n",
    "(-589.75, -594.71, -599.54, -601.54, -602.75, -603.28, -604.28, -604.79, -605.55, -606.29)\n",
    "Distance from Goal: (0.014, 0.005, -0.017)\n",
    "\"\"\"\n",
    "\n",
    "# Set to identity unless you want the goal to have a certain orientation.\n",
    "EE_ROT_TGT = np.asmatrix([[0.6867, 0.5401067, 0.48645617], \n",
    "                          [-0.4588635, -0.19689, 0.866416],\n",
    "                          [0.56373678, -0.58105, 0.18935]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only edit these when editing the robot joints and links. \n",
    "# The lengths of these arrays define numerous parameters in GPS.\n",
    "JOINT_ORDER = [L_SHOULDER_PITCH, L_SHOULDER_ROLL, L_ELBOW_YAW, L_ELBOW_ROLL,\n",
    "               L_WRIST_YAW, L_GRASP]\n",
    "LINK_NAMES = [TORSO, L_SHOULDER, L_BICEP, L_FOREARM,\n",
    "              L_WRIST, L_GRIPPER]\n",
    "\n",
    "# Hyperparamters to be tuned for optimizing policy learning on the specific robot.\n",
    "PEPPER_GAINS = np.array([1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Packaging sensor dimensional data for refernece.\n",
    "SENSOR_DIMS = {\n",
    "    JOINT_ANGLES: len(JOINT_ORDER),\n",
    "    JOINT_VELOCITIES: len(JOINT_ORDER),\n",
    "    END_EFFECTOR_POINTS: NUM_EE_POINTS * EE_POINTS.shape[1],\n",
    "    END_EFFECTOR_POINT_VELOCITIES: NUM_EE_POINTS * EE_POINTS.shape[1],\n",
    "    ACTION: len(PEPPER_GAINS),\n",
    "}\n",
    "\n",
    "\n",
    "# States to check in agent._process_observations.\n",
    "STATE_TYPES = {'positions': JOINT_ANGLES,\n",
    "               'velocities': JOINT_VELOCITIES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to urdf of robot.\n",
    "TREE_PATH = os.environ['PEPPER_PATH'] + '/pepper_robot/pepper_description/urdf/pepper1.0_generated_urdf/pepper.urdf'\n",
    "# Be sure to specify the correct experiment directory to save policy data at.\n",
    "BASE_DIR = '/'.join(str.split(gps_filepath, '/')[:-2])\n",
    "EXP_DIR = BASE_DIR + '/../experiments/pepper_example/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of seconds per step of a sample.\n",
    "TIMESTEP     = 0.01 # Typically 0.01.\n",
    "# Set the number of timesteps per sample.\n",
    "STEP_COUNT   = 100 # Typically 100.\n",
    "# Set the number of samples per condition.\n",
    "SAMPLE_COUNT = 5 # Typically 5.\n",
    "# set the number of conditions per iteration.\n",
    "CONDITIONS   = 1 # Typically 2 for Caffe and 1 for LQR.\n",
    "# Set the number of trajectory iterations to collect.\n",
    "ITERATIONS   = 10 # Typically 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0s = []\n",
    "ee_tgts = []\n",
    "reset_conditions = []\n",
    "\n",
    "common = {\n",
    "    'experiment_name': 'my_experiment' + '_' + \\\n",
    "            datetime.strftime(datetime.now(), '%m-%d-%y_%H-%M'),\n",
    "    'experiment_dir': EXP_DIR,\n",
    "    'data_files_dir': EXP_DIR + 'data_files/',\n",
    "    'target_filename': EXP_DIR + 'target.npz',\n",
    "    'log_filename': EXP_DIR + 'log.txt',\n",
    "    'conditions': CONDITIONS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up each condition.\n",
    "for i in xrange(common['conditions']):\n",
    "\n",
    "    # Use hardcoded default vals init and target locations\n",
    "    ja_x0 = np.zeros(SENSOR_DIMS[JOINT_ANGLES])\n",
    "    ee_pos_x0 = np.zeros((1, 3))\n",
    "    ee_rot_x0 = np.zeros((3, 3))\n",
    "    \n",
    "    ee_pos_tgt = EE_POS_TGT\n",
    "    ee_rot_tgt = EE_ROT_TGT\n",
    "\n",
    "    state_space = sum(SENSOR_DIMS.values()) - SENSOR_DIMS[ACTION]\n",
    "\n",
    "    joint_dim = SENSOR_DIMS[JOINT_ANGLES] + SENSOR_DIMS[JOINT_VELOCITIES]\n",
    "\n",
    "    # Initialized to start position and inital velocities are 0\n",
    "    x0 = np.zeros(state_space)\n",
    "    x0[:SENSOR_DIMS[JOINT_ANGLES]] = ja_x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Need for this node will go away upon migration to KDL\n",
    "    rospy.init_node('gps_agent_pepper_node')\n",
    "    \n",
    "    # Set starting end effector position using TF\n",
    "    tf = TransformListener()\n",
    "\n",
    "    # Sleep for .1 secs to give the node a chance to kick off\n",
    "    rospy.sleep(1)\n",
    "    time = tf.getLatestCommonTime(L_GRIPPER, TORSO)\n",
    "\n",
    "    x0[joint_dim:(joint_dim + NUM_EE_POINTS * EE_POINTS.shape[1])] = get_position(tf, L_GRIPPER, TORSO, time)\n",
    "\n",
    "    # Initialize target end effector position\n",
    "    ee_tgt = np.ndarray.flatten(\n",
    "        get_ee_points(EE_POINTS, ee_pos_tgt, ee_rot_tgt).T\n",
    "    )\n",
    "\n",
    "    reset_condition = {\n",
    "        JOINT_ANGLES: INITIAL_JOINTS,\n",
    "        JOINT_VELOCITIES: []\n",
    "    }\n",
    "\n",
    "    x0s.append(x0)\n",
    "    ee_tgts.append(ee_tgt)\n",
    "    reset_conditions.append(reset_condition)\n",
    "\n",
    "\n",
    "if not os.path.exists(common['data_files_dir']):\n",
    "    os.makedirs(common['data_files_dir'])\n",
    "\n",
    "agent = {\n",
    "    'type': AgentPEPPER,\n",
    "    'dt': TIMESTEP,\n",
    "    'dU': SENSOR_DIMS[ACTION],\n",
    "    'conditions': common['conditions'],\n",
    "    'T': STEP_COUNT,\n",
    "    'x0': x0s,\n",
    "    'ee_points_tgt': ee_tgts,\n",
    "    'reset_conditions': reset_conditions,\n",
    "    'sensor_dims': SENSOR_DIMS,\n",
    "    'joint_order': JOINT_ORDER,\n",
    "    'link_names': LINK_NAMES,\n",
    "    'state_types': STATE_TYPES,\n",
    "    'tree_path': TREE_PATH,\n",
    "    'joint_publisher': JOINT_PUBLISHER,\n",
    "    'joint_subscriber': JOINT_SUBSCRIBER,\n",
    "    'slowness': SLOWNESS,\n",
    "    'reset_slowness': RESET_SLOWNESS,\n",
    "    'state_include': [JOINT_ANGLES, JOINT_VELOCITIES,\n",
    "                      END_EFFECTOR_POINTS, END_EFFECTOR_POINT_VELOCITIES],\n",
    "    'end_effector_points': [EE_POINTS],\n",
    "    'obs_include': [],\n",
    "}\n",
    "\n",
    "algorithm = {\n",
    "    'type': AlgorithmTrajOpt,\n",
    "    'conditions': common['conditions'],\n",
    "    'iterations': ITERATIONS,\n",
    "}\n",
    "\n",
    "algorithm['init_traj_distr'] = {\n",
    "    'type': init_lqr,\n",
    "    'init_gains': 1.0 / PEPPER_GAINS,\n",
    "    'init_acc': np.zeros(SENSOR_DIMS[ACTION]),\n",
    "    'init_var': 1.0,\n",
    "    'stiffness': 0.5,\n",
    "    'stiffness_vel': .25,\n",
    "    'final_weight': 50,\n",
    "    'dt': agent['dt'],\n",
    "    'T': agent['T'],\n",
    "}\n",
    "\n",
    "# This cost function takes into account the distance between the end effector's\n",
    "# current and target positions, weighted in a linearly increasing fassion\n",
    "# as the number of trials grows from 0 to T-1.  \n",
    "fk_cost_ramp = {\n",
    "    'type': CostFK,\n",
    "    # Target end effector is subtracted out of EE_POINTS in pr2 c++ plugin so goal\n",
    "    # is 0. The UR agent also subtracts this out for consistency.\n",
    "    'target_end_effector': [np.zeros(NUM_EE_POINTS * EE_POINTS.shape[1])],\n",
    "    'wp': np.ones(SENSOR_DIMS[END_EFFECTOR_POINTS]),\n",
    "    'l1': 0.1,\n",
    "    'l2': 0.0001,\n",
    "    'ramp_option': RAMP_LINEAR,\n",
    "}\n",
    "\n",
    "# This cost function takes into account the distance between the end effector's\n",
    "# current and target positions at time T-1 only.\n",
    "fk_cost_final = {\n",
    "    'type': CostFK,\n",
    "    'target_end_effector': np.zeros(NUM_EE_POINTS * EE_POINTS.shape[1]),\n",
    "    'wp': np.ones(SENSOR_DIMS[END_EFFECTOR_POINTS]),\n",
    "    'l1': 1.0,\n",
    "    'l2': 0.0,\n",
    "    'wp_final_multiplier': 100.0,  # Weight multiplier on final timestep.\n",
    "    'ramp_option': RAMP_FINAL_ONLY,\n",
    "}\n",
    "\n",
    "# Combines the cost functions in 'costs' to produce a single cost function\n",
    "algorithm['cost'] = {\n",
    "    'type': CostSum,\n",
    "    'costs': [fk_cost_ramp, fk_cost_final],\n",
    "    'weights': [1.0, 1.0],\n",
    "}\n",
    "\n",
    "algorithm['dynamics'] = {\n",
    "    'type': DynamicsLRPrior,\n",
    "    'regularization': 1e-6,\n",
    "    'prior': {\n",
    "        'type': DynamicsPriorGMM,\n",
    "        'max_clusters': 20,\n",
    "        'min_samples_per_cluster': 40,\n",
    "        'max_samples': 20,\n",
    "    },\n",
    "}\n",
    "\n",
    "algorithm['traj_opt'] = {\n",
    "    'type': TrajOptLQRPython,\n",
    "}\n",
    "\n",
    "algorithm['policy_opt'] = {}\n",
    "\n",
    "config = {\n",
    "    'iterations': algorithm['iterations'],\n",
    "    'common': common,\n",
    "    'verbose_trials': 0,\n",
    "    'agent': agent,\n",
    "    'gui_on': True,\n",
    "    'algorithm': algorithm,\n",
    "    'num_samples': SAMPLE_COUNT,\n",
    "}\n",
    "\n",
    "common['info'] = generate_experiment_info(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
